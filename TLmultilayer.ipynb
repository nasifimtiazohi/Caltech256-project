{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#CHANGE THIS to aboslute path of Caltech repo\n",
    "os.chdir('/Users/nasifimtiaz/Desktop/Caltech256-project')\n",
    "#this is a global variable to set how many subset of classes we will work with \n",
    "#CHANGE THIS TO REQUIRED NUMBER (257) while running on GPU\n",
    "working_classes=257"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "#images are in different shapes. needs to square them.\n",
    "def shrink_square(img, shrink_size, color_mode, fill_color):\n",
    "    #all the images will be shrinked to shrink_size with any leftover filled with color_fill\n",
    "    ## thumbnail resizes image while maintaining aspect ratio\n",
    "    shrinked_img=img.thumbnail((shrink_size,shrink_size),Image.ANTIALIAS)\n",
    "    \n",
    "    #if some images were originally less than shrink_size, bring to shrink size by filling the leftover\n",
    "    output=Image.new(color_mode,(shrink_size,shrink_size),fill_color)\n",
    "    output.paste(img, (int((shrink_size - img.size[0]) / 2), int((shrink_size - img.size[1]) / 2)))\n",
    "    \n",
    "    return output\n",
    "\n",
    "\n",
    "#turn images to np_array\n",
    "def image_to_tensors(img):\n",
    "    arr=np.array(img)\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#globally setting up the square size that all images will be resized to\n",
    "img_size=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hm={}\n",
    "path='./256_ObjectCategories'\n",
    "folders=os.listdir(path)\n",
    "\n",
    "\n",
    "for folder in folders:\n",
    "    os.chdir(path+'/'+folder)\n",
    "    image_paths=os.listdir()\n",
    "    class_images=[]\n",
    "    for i in image_paths:\n",
    "        if i[-4:]=='.jpg':\n",
    "            print(\"processing \",i)\n",
    "            img=Image.open(i)\n",
    "            shrinked_img=shrink_square(img, img_size, 'RGB', 0)\n",
    "            img_arr=image_to_tensors(shrinked_img)\n",
    "            img_arr=img_arr/255 #scaling pixel values to [0,1]\n",
    "            class_images.append(img_arr)\n",
    "            img.close()\n",
    "            shrinked_img.close()\n",
    "    class_name= folder.split('.')[1]\n",
    "    hm[class_name]=class_images\n",
    "    os.chdir('../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert hm to X,y data mapping\n",
    "#where each row of X is an image, y is it's class in int\n",
    "import random\n",
    "def make_Xy(hm, subset_classes):\n",
    "    classes=list(hm.keys())\n",
    "    random.shuffle(classes)\n",
    "    classes=classes[0:subset_classes]\n",
    "    X=[]\n",
    "    y=[]\n",
    "    for key in classes:\n",
    "        images=hm[key]\n",
    "        X.extend(images)\n",
    "        y.extend([key]*len(images))\n",
    "    X=np.array(X)\n",
    "    y=pd.get_dummies(y)\n",
    "    \n",
    "    return X,y     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"started\")\n",
    "X,y=make_Xy(hm,subset_classes=working_classes)\n",
    "print(X.shape,y.shape)\n",
    "#make a test train split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    stratify=y, \n",
    "                                                    test_size=0.20)\n",
    "print(\"finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "import keras.backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "import keras.backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPool2D, AvgPool2D,Flatten\n",
    "from keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import CSVLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_plots(history, prefix):\n",
    "    training_loss = history['loss']\n",
    "    validation_loss = history['val_loss']\n",
    "    accuracy = history['accuracy']\n",
    "    val_accuracy=history['val_accuracy']\n",
    "    epochs=range(1,len(accuracy)+1)\n",
    "    \n",
    "    plt.plot(epochs,training_loss,'bo',label='Training loss')\n",
    "    plt.plot(epochs,validation_loss,'b',label='Test loss')\n",
    "    plt.title('Training and test loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(prefix + '_1.png',dpi=500)\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "    \n",
    "    plt.plot(epochs,accuracy,'b',label='Training accuracy')\n",
    "    plt.plot(epochs,val_accuracy,'r',label='Test accuracy')\n",
    "    plt.title('Training and test accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.savefig(prefix + '_2.png',dpi=500)\n",
    "    plt.show()\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TLmodel2(input_dim, output_classes):\n",
    "    \n",
    "    vgg_base = VGG16(weights='imagenet', include_top=False, input_shape=input_dim)\n",
    "    \n",
    "    print(vgg_base.summary())\n",
    "    \n",
    "    model= Sequential()\n",
    "    model.add(vgg_base)\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(Dense(1024,activation='relu'))\n",
    "    model.add(Dense(512,activation='relu'))\n",
    "    model.add(Dense(output_classes,activation='softmax'))\n",
    "\n",
    "    print(len(model.trainable_weights))\n",
    "    \n",
    "    vgg_base.trainable=False\n",
    "    \n",
    "    print(len(model.trainable_weights))\n",
    "\n",
    "\n",
    "    adam = Adam(lr=0.001)\n",
    "    model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    \n",
    "    return model\n",
    "\n",
    "model= TLmodel2((img_size,img_size,3), working_classes)\n",
    "generator = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n",
    "csv_logger = CSVLogger('./Caltech256TL.csv', append=False, separator=',')\n",
    "print(\"a\")\n",
    "fit=model.fit_generator(generator.flow(X_train, y_train.values, batch_size=32), \n",
    "                        epochs=10,verbose=1,validation_data=(X_test, y_test.values), callbacks=[csv_logger])\n",
    "validation_plots(fit.history,\"ANN\")\n",
    "print(model.evaluate(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TLmodel3(input_dim, output_classes):\n",
    "    \n",
    "    vgg_base = VGG16(weights='imagenet', include_top=False, input_shape=input_dim)\n",
    "    \n",
    "    print(vgg_base.summary())\n",
    "    \n",
    "    model= Sequential()\n",
    "    model.add(vgg_base)\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(Dense(2048,activation='relu'))\n",
    "    model.add(Dense(1024,activation='relu'))\n",
    "    model.add(Dense(512,activation='relu'))\n",
    "    model.add(Dense(output_classes,activation='softmax'))\n",
    "\n",
    "    print(len(model.trainable_weights))\n",
    "    \n",
    "    vgg_base.trainable=False\n",
    "    \n",
    "    print(len(model.trainable_weights))\n",
    "\n",
    "\n",
    "    adam = Adam(lr=0.001)\n",
    "    model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    \n",
    "    return model\n",
    "\n",
    "model= TLmodel3((img_size,img_size,3), working_classes)\n",
    "generator = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n",
    "csv_logger = CSVLogger('./Caltech256TL.csv', append=False, separator=',')\n",
    "print(\"a\")\n",
    "fit=model.fit_generator(generator.flow(X_train, y_train.values, batch_size=32), \n",
    "                        epochs=10,verbose=1,validation_data=(X_test, y_test.values), callbacks=[csv_logger])\n",
    "validation_plots(fit.history,\"ANN\")\n",
    "print(model.evaluate(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras",
   "language": "python",
   "name": "build_central"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
