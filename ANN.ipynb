{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#CHANGE THIS to aboslute path of Caltech repo\n",
    "os.chdir('./')\n",
    "#this is a global variable to set how many subset of classes we will work with \n",
    "#CHANGE THIS TO REQUIRED NUMBER (257) while running on GPU\n",
    "working_classes=257"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "#images are in different shapes. needs to square them.\n",
    "def shrink_square(img, shrink_size, color_mode, fill_color):\n",
    "    #all the images will be shrinked to shrink_size with any leftover filled with color_fill\n",
    "    ## thumbnail resizes image while maintaining aspect ratio\n",
    "    shrinked_img=img.thumbnail((shrink_size,shrink_size),Image.ANTIALIAS)\n",
    "    \n",
    "    #if some images were originally less than shrink_size, bring to shrink size by filling the leftover\n",
    "    output=Image.new(color_mode,(shrink_size,shrink_size),fill_color)\n",
    "    output.paste(img, (int((shrink_size - img.size[0]) / 2), int((shrink_size - img.size[1]) / 2)))\n",
    "    \n",
    "    return output\n",
    "\n",
    "\n",
    "#turn images to np_array\n",
    "def image_to_tensors(img):\n",
    "    arr=np.array(img)\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#globally setting up the square size that all images will be resized to\n",
    "img_size=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hm={}\n",
    "path='./256_ObjectCategories'\n",
    "folders=os.listdir(path)\n",
    "\n",
    "\n",
    "for folder in folders:\n",
    "    os.chdir(path+'/'+folder)\n",
    "    image_paths=os.listdir()\n",
    "    class_images=[]\n",
    "    for i in image_paths:\n",
    "        if i[-4:]=='.jpg':\n",
    "            print(\"processing \",i)\n",
    "            img=Image.open(i)\n",
    "            shrinked_img=shrink_square(img, img_size, 'RGB', 0)\n",
    "            img_arr=image_to_tensors(shrinked_img)\n",
    "            img_arr=img_arr/255 #scaling pixel values to [0,1]\n",
    "            class_images.append(img_arr)\n",
    "            img.close()\n",
    "            shrinked_img.close()\n",
    "    class_name= folder.split('.')[1]\n",
    "    hm[class_name]=class_images\n",
    "    os.chdir('../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert hm to X,y data mapping\n",
    "#where each row of X is an image, y is it's class in int\n",
    "import random\n",
    "def make_Xy(hm, subset_classes):\n",
    "    classes=list(hm.keys())\n",
    "    random.shuffle(classes)\n",
    "    classes=classes[0:subset_classes]\n",
    "    X=[]\n",
    "    y=[]\n",
    "    for key in classes:\n",
    "        images=hm[key]\n",
    "        X.extend(images)\n",
    "        y.extend([key]*len(images))\n",
    "    X=np.array(X)\n",
    "    y=pd.get_dummies(y)\n",
    "    \n",
    "    return X,y     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y=make_Xy(hm,subset_classes=working_classes)\n",
    "#make a test train split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    stratify=y, \n",
    "                                                    test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "import keras.backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "import keras.backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPool2D, AvgPool2D,Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import CSVLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DenseNetwork(X_train,y_train,input_dim,output_classes,\n",
    "                 hidden_layer=2,units=[2048,2048], kernel_initializer='RandomNormal', \n",
    "                 hidden_layer_activation='relu',output_layer_activation='softmax', \n",
    "                 loss='categorical_crossentropy',metrics=['accuracy'],learning_rate=.1,\n",
    "                 dropout=.5,batch_size=32,epochs=80):\n",
    "    \n",
    "    csv_logger = CSVLogger('./Caltech256ANN.csv', append=False, separator=',')\n",
    "    \n",
    "    #flatten the images first for dense network\n",
    "    X_train=X_train.reshape(X_train.shape[0],-1)\n",
    "    \n",
    "    model= Sequential()\n",
    "    \n",
    "    for i in range(0,hidden_layer):\n",
    "        model.add(Dense(units=units[0],kernel_initializer=kernel_initializer,input_dim=input_dim))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation(hidden_layer_activation))\n",
    "        model.add(Dropout(dropout))\n",
    "\n",
    "\n",
    "    model.add(Dense(output_classes,kernel_initializer=kernel_initializer,activation=output_layer_activation))\n",
    "    model.compile(Adam(lr=learning_rate),loss=loss,metrics=metrics)\n",
    "\n",
    "    fit=model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, \n",
    "                  validation_data=(X_test.reshape(X_test.shape[0],-1),y_test), callbacks=[csv_logger])\n",
    "    \n",
    "    return model, fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_plots(history, prefix):\n",
    "    training_loss = history['loss']\n",
    "    validation_loss = history['val_loss']\n",
    "    accuracy = history['accuracy']\n",
    "    val_accuracy=history['val_accuracy']\n",
    "    epochs=range(1,len(accuracy)+1)\n",
    "    \n",
    "    plt.plot(epochs,training_loss,'bo',label='Training loss')\n",
    "    plt.plot(epochs,validation_loss,'b',label='Test loss')\n",
    "    plt.title('Training and test loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(prefix + '_1.png',dpi=500)\n",
    "    plt.show()\n",
    "    \n",
    "    plt.plot(epochs,accuracy,'b',label='Training accuracy')\n",
    "    plt.plot(epochs,val_accuracy,'r',label='Test accuracy')\n",
    "    plt.title('Training and test accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.savefig(prefix + '_2.png',dpi=500)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_model, dense_fit = DenseNetwork(X_train,y_train,img_size*img_size*3,working_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_plots(dense_fit.history,\"ANN\")\n",
    "print(dense_model.evaluate(X_test.reshape(X_test.shape[0],-1),y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras",
   "language": "python",
   "name": "build_central"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
